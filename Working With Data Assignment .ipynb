{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "\n",
    "#Use this cell to ignore the warnings.\n",
    "\n",
    "#[Your Code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the numpy and pandas packages\n",
    "\n",
    "#[Your Code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Reading and Inspection\n",
    "\n",
    "-  ### Subtask 1.1: Import and read\n",
    "\n",
    "Import and read the movie data. Store it in a variable called `movies`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the numpy and pandas packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "movies = pd.read_csv('Desktop/assigment/MovieData.csv/movies.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Making Sure that the csv file belong to the same directory as this file. And then using head command to read few rows.\n",
    "#Else complete path of the directory can be used to read the file.\n",
    "#read_csv is used to read the deimited file.\n",
    "\n",
    "#[Your Code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 1.2: Inspect the dataframe\n",
    "\n",
    "Inspect the dataframe's columns, shapes, variable types etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the first few rows of the dataframe\n",
    "print(movies.head())\n",
    "\n",
    "# Inspect the dataframe's columns, shapes, and variable types\n",
    "print(movies.info())\n",
    "print(movies.shape)\n",
    "print(movies.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Cleaning the Data\n",
    "\n",
    "-  ### Subtask 2.1: Inspect Null values\n",
    "\n",
    "Find out the number of Null values in all the columns and rows. Also, find the percentage of Null values in each column. Round off the percentages upto two decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for column-wise null count here\n",
    "\n",
    "#Hint : isnull returns boolean True/False for column value to be null or not, sum will add int count. \n",
    "\n",
    "print(movies.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for row-wise null count here\n",
    "\n",
    "#Sum of ISNull along axis 1 will give the null count row-wise. \n",
    "print(movies.isnull().sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for column-wise null percentages here\n",
    "\n",
    "# Sum of all nulls of column/Total count converted to percentage and rounded to 2 digits.\n",
    "\n",
    "print((movies.isnull().sum() / len(movies)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 2.2: Drop unecessary columns\n",
    "\n",
    "For this assignment, you will mostly be analyzing the movies with respect to the ratings, gross collection, popularity of movies, etc. So many of the columns in this dataframe are not required. So it is advised to drop the following columns.\n",
    "-  color\n",
    "-  director_facebook_likes\n",
    "-  actor_1_facebook_likes\n",
    "-  actor_2_facebook_likes\n",
    "-  actor_3_facebook_likes\n",
    "-  actor_2_name\n",
    "-  cast_total_facebook_likes\n",
    "-  actor_3_name\n",
    "-  duration\n",
    "-  facenumber_in_poster\n",
    "-  content_rating\n",
    "-  country\n",
    "-  movie_imdb_link\n",
    "-  aspect_ratio\n",
    "-  plot_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for dropping the columns here. It is advised to keep inspecting the dataframe after each set of operations \n",
    "\n",
    "#Dropping the columns which are not required.Written in Multiple lines for readbility.\n",
    "\n",
    "# Drop unnecessary columns\n",
    "columns_to_drop = ['color', 'director_facebook_likes', 'actor_1_facebook_likes', 'actor_2_facebook_likes',\n",
    "                   'actor_3_facebook_likes', 'actor_2_name', 'cast_total_facebook_likes', 'actor_3_name',\n",
    "                   'duration', 'facenumber_in_poster', 'content_rating', 'country', 'movie_imdb_link',\n",
    "                   'aspect_ratio', 'plot_keywords']\n",
    "\n",
    "movies = movies.drop(columns=columns_to_drop)\n",
    "\n",
    "# Inspect the dataframe after dropping columns\n",
    "print(movies.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 2.3: Drop unecessary rows using columns with high Null percentages\n",
    "\n",
    "Now, on inspection you might notice that some columns have large percentage (greater than 5%) of Null values. Drop all the rows which have Null values for such columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with Null values in columns with high percentages\n",
    "high_null_columns = ['column1', 'column2', ...]  # Replace with the actual column names\n",
    "movies = movies.dropna(subset=high_null_columns, thresh=1)  # Set the threshold as needed\n",
    "\n",
    "# Inspect the dataframe after dropping rows\n",
    "print(movies.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 2.4: Drop unecessary rows\n",
    "\n",
    "Some of the rows might have greater than five NaN values. Such rows aren't of much use for the analysis and hence, should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with more than five NaN values\n",
    "movies = movies.dropna(thresh=5)\n",
    "\n",
    "# Inspect the dataframe after dropping rows\n",
    "print(movies.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 2.5: Fill NaN values\n",
    "\n",
    "You might notice that the `language` column has some NaN values. Here, on inspection, you will see that it is safe to replace all the missing values with `'English'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values in the 'language' column with 'English'\n",
    "movies['language'].fillna('English', inplace=True)\n",
    "\n",
    "# Verify that NaN values are filled\n",
    "print(movies['language'].isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 2.6: Check the number of retained rows\n",
    "\n",
    "You might notice that two of the columns viz. `num_critic_for_reviews` and `actor_1_name` have small percentages of NaN values left. You can let these columns as it is for now. Check the number and percentage of the rows retained after completing all the tasks above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of retained rows\n",
    "print(movies.shape[0])  # Number of rows\n",
    "print((movies.shape[0] / len(movies)) * 100)  # Percentage of retained rows\n",
    "# Write your code for checking number of retained rows here\n",
    "#[Your Code]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint 1:** You might have noticed that we still have around `77%` of the rows!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Data Analysis\n",
    "\n",
    "-  ### Subtask 3.1: Change the unit of columns\n",
    "\n",
    "Convert the unit of the `budget` and `gross` columns from `$` to `million $`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['budget'] = movies['budget'] / 1000000\n",
    "movies['gross'] = movies['gross'] / 1000000\n",
    "\n",
    "# Verify the changes\n",
    "print(movies[['budget', 'gross']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 3.2: Find the movies with highest profit\n",
    "\n",
    "    1. Create a new column called `profit` which contains the difference of the two columns: `gross` and `budget`.\n",
    "    2. Sort the dataframe using the `profit` column as reference.\n",
    "    3. Extract the top ten profiting movies in descending order and store them in a new dataframe - `top10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for creating the profit column here\n",
    "movies['profit'] = movies['gross'] - movies['budget']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for sorting the dataframe here\n",
    "movies = movies.sort_values(by='profit', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the top ten profiting movies\n",
    "top10 = movies.head(10)\n",
    "\n",
    "# Inspect the top10 dataframe\n",
    "print(top10[['movie_title', 'profit']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 3.3: Drop duplicate values\n",
    "\n",
    "After you found out the top 10 profiting movies, you might have notice a duplicate value. So, it seems like the dataframe has duplicate values as well. Drop the duplicate values from the dataframe and repeat `Subtask 3.2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for drmovies = movies.drop_duplicates()\n",
    "movies = movies.drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write code for repeating subtask 2 here\n",
    "top10 = movies.head(10)\n",
    "#Sort df by profit in descending order.Print Top 10 movies for verification.\n",
    "print(top10[['movie_title', 'profit']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint 2:** You might spot two movies directed by `James Cameron` in the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 3.4: Find IMDb Top 250\n",
    "\n",
    "    1. Create a new dataframe `IMDb_Top_250` and store the top 250 movies with the highest IMDb Rating (corresponding to the column: `imdb_score`). Also make sure that for all of these movies, the `num_voted_users` is greater than 25,000.\n",
    "Also add a `Rank` column containing the values 1 to 250 indicating the ranks of the corresponding films.\n",
    "    2. Extract all the movies in the `IMDb_Top_250` dataframe which are not in the English language and store them in a new dataframe named `Top_Foreign_Lang_Film`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for extracting the top 250 movies as per the IMDb score here. Make sure that you store it in a new dataframe \n",
    "IMDb_Top_250 = movies[movies['num_voted_users'] > 25000].nlargest(250, 'imdb_score')\n",
    "\n",
    "# and name that dataframe as 'IMDb_Top_250'\n",
    "IMDb_Top_250['Rank'] = range(1, 251)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Taking rows whoes language column value is not English.\n",
    "print(IMDb_Top_250[['movie_title', 'imdb_score', 'num_voted_users', 'Rank']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint 3:** Can you spot `Veer-Zaara` in the dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Subtask 3.5: Find the best directors\n",
    "\n",
    "    1. Group the dataframe using the `director_name` column.\n",
    "    2. Find out the top 10 directors for whom the mean of `imdb_score` is the highest and store them in a new dataframe `top10director`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by 'director_name' and calculate the mean of 'imdb_score'\n",
    "director_scores = movies.groupby('director_name')['imdb_score'].mean()\n",
    "\n",
    "# Find the top 10 directors with the highest mean imdb_score\n",
    "top10director = director_scores.nlargest(10).reset_index()\n",
    "\n",
    "# Inspect the top10director dataframe\n",
    "print(top10director[['director_name', 'imdb_score']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint 4:** No surprises that `Damien Chazelle` (director of Whiplash and La La Land) is in this list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 3.6: Find popular genres\n",
    "\n",
    "You might have noticed the `genres` column in the dataframe with all the genres of the movies seperated by a pipe (`|`). Out of all the movie genres, the first two are most significant for any film.\n",
    "\n",
    "1. Extract the first two genres from the `genres` column and store them in two new columns: `genre_1` and `genre_2`. Some of the movies might have only one genre. In such cases, extract the single genre into both the columns, i.e. for such movies the `genre_2` will be the same as `genre_1`.\n",
    "2. Group the dataframe using `genre_1` as the primary column and `genre_2` as the secondary column.\n",
    "3. Find out the 5 most popular combo of genres by finding the mean of the gross values using the `gross` column and store them in a new dataframe named `PopGenre`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code for extracting the first two genres of each movie here\n",
    "movies['genre_1'] = movies['genres'].str.split('|').str[0]\n",
    "movies['genre_2'] = movies['genres'].str.split('|').str[1].fillna(movies['genre_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Movies has been grouped by genre_1 and then genre_2\n",
    "genre_grouped = movies.groupby(['genre_1', 'genre_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pivot table can be used to calculate the mean gross and then group by genres. And then sorted by the gross value.\n",
    "PopGenre = genre_grouped['gross'].mean().sort_values(ascending=False).reset_index()\n",
    "\n",
    "# Inspect the PopGenre dataframe\n",
    "print(PopGenre.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint 5:** Well, as it turns out. `Family + Sci-Fi` is the most popular combo of genres out there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  ### Subtask 3.7: Find the critic-favorite and audience-favorite actors\n",
    "\n",
    "    1. Create three new dataframes namely, `Meryl_Streep`, `Leo_Caprio`, and `Brad_Pitt` which contain the movies in which the actors: 'Meryl Streep', 'Leonardo DiCaprio', and 'Brad Pitt' are the lead actors. Use only the `actor_1_name` column for extraction. Also, make sure that you use the names 'Meryl Streep', 'Leonardo DiCaprio', and 'Brad Pitt' for the said extraction.\n",
    "    2. Append the rows of all these dataframes and store them in a new dataframe named `Combined`.\n",
    "    3. Group the combined dataframe using the `actor_1_name` column.\n",
    "    4. Find the mean of the `num_critic_for_reviews` and `num_user_for_review` and identify the actors which have the highest mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  actor_1_name      0\n",
      "0    Brad Pitt  370.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming you have a DataFrame named 'movies' or load it from a file\n",
    "# For example, you can create a sample DataFrame like this:\n",
    "movies_data = {\n",
    "    'Movie_Name': ['Movie1', 'Movie2', 'Movie3'],\n",
    "    'actor_1_name': ['Meryl Streep', 'Leonardo DiCaprio', 'Brad Pitt'],\n",
    "    'num_critic_for_reviews': [100, 120, 150],\n",
    "    'num_user_for_reviews': [200, 180, 220]\n",
    "}\n",
    "\n",
    "movies = pd.DataFrame(movies_data)\n",
    "\n",
    "# Now you can run the code you provided\n",
    "Meryl_Streep = movies[movies['actor_1_name'] == 'Meryl Streep']\n",
    "Leo_Caprio = movies[movies['actor_1_name'] == 'Leonardo DiCaprio']\n",
    "Brad_Pitt = movies[movies['actor_1_name'] == 'Brad Pitt']\n",
    "\n",
    "# Append the rows of these dataframes\n",
    "Combined = pd.concat([Meryl_Streep, Leo_Caprio, Brad_Pitt])\n",
    "\n",
    "# Group the Combined dataframe by 'actor_1_name'\n",
    "actor_grouped = Combined.groupby('actor_1_name')\n",
    "\n",
    "# Find the mean of 'num_critic_for_reviews' and 'num_user_for_reviews'\n",
    "actor_reviews = actor_grouped[['num_critic_for_reviews', 'num_user_for_reviews']].mean()\n",
    "\n",
    "# Identify actors with the highest mean reviews\n",
    "top_actor_reviews = actor_reviews.sum(axis=1).nlargest(1).reset_index()\n",
    "\n",
    "# Inspect the top_actor_reviews dataframe\n",
    "print(top_actor_reviews)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mean critic Review and Mean audience review grouped by the actor's name in above combined data frame\n",
    "#Using pivot to grorup by both and then get sorted mean.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checkpoint 6:** `Leonardo` has aced both the lists!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
